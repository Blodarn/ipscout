{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06abd345-fff7-4fc0-9335-ef30775d8884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0a06e3b46547539628248742c1fdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>IP Lookup Tool</h2>'), Text(value='', description='IP(s):', layout=Layout(width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import socket\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from ipywidgets import widgets, VBox, HBox, Output\n",
    "from IPython.display import display\n",
    "import time\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "############\n",
    "# API KEYS #\n",
    "############\n",
    "api_key_abuseipdb = \"<YOUR-API-KEY-HERE>\"\n",
    "api_key_ipgeo = \"<YOUR-API-KEY-HERE>\"\n",
    "api_key_ipinfo = \"<YOUR-API-KEY-HERE>\"\n",
    "\n",
    "###################\n",
    "# Global variable #\n",
    "###################\n",
    "# To store the most recently displayed DataFrame\n",
    "exported_df = None\n",
    "\n",
    "#############\n",
    "# FUNCTIONS #\n",
    "#############\n",
    "\n",
    "#### AbuseIPDB Functions ####\n",
    "def fetch_abuseipdb_data(ip, api_key):\n",
    "    \"\"\"Fetch abuse data for a single IP from AbuseIPDB.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"https://api.abuseipdb.com/api/v2/check?ipAddress={ip}\",\n",
    "            headers={'Accept': 'application/json', 'Key': api_key},\n",
    "            timeout=10\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"IP\": ip,\n",
    "            \"Abuse Score\": data.get(\"data\", {}).get(\"abuseConfidenceScore\", \"N/A\"),\n",
    "            \"ISP\": data.get(\"data\", {}).get(\"isp\", \"N/A\"),\n",
    "            \"Reports\": data.get(\"data\", {}).get(\"totalReports\", \"N/A\"),\n",
    "            \"Last Reported\": data.get(\"data\", {}).get(\"lastReportedAt\", \"N/A\"),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"IP Address\": ip, \"Error\": str(e)}\n",
    "\n",
    "def check_abuseipdb_bulk(api_key, ip_list):\n",
    "    \"\"\"Check multiple IPs using AbuseIPDB.\"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(fetch_abuseipdb_data, ip, api_key): ip for ip in ip_list}\n",
    "        \n",
    "        with tqdm(total=len(ip_list), desc=\"    Checking AbuseIPDB\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                results.append(future.result())\n",
    "                pbar.update(1)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "#### IPGeolocation.io Functions ####\n",
    "def resolve_hostname_to_ip(hostname):\n",
    "    \"\"\"Resolve a hostname to an IP address.\"\"\"\n",
    "    try:\n",
    "        return socket.gethostbyname(hostname)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def fetch_ipgeo_data(ip, api_key):\n",
    "    \"\"\"Fetch data for a single IP from IPGeolocation.io.\"\"\"\n",
    "    url = f\"https://api.ipgeolocation.io/v2/ipgeo?apiKey={api_key}&ip={ip}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"IP\": ip,\n",
    "            \"Continent\": data.get(\"location\", {}).get(\"continent_name\", \"N/A\"),\n",
    "            \"Country\": data.get(\"location\", {}).get(\"country_name\", \"N/A\"),\n",
    "            \"State\": data.get(\"location\", {}).get(\"state_prov\", \"N/A\"),\n",
    "            \"District\": data.get(\"location\", {}).get(\"district\", \"N/A\"),\n",
    "            \"City\": data.get(\"location\", {}).get(\"city\", \"N/A\"),\n",
    "            \"Zip code\": data.get(\"location\", {}).get(\"zipcode\", \"N/A\"),\n",
    "            \"Latitude\": data.get(\"location\", {}).get(\"latitude\", \"N/A\"),\n",
    "            \"Longitude\": data.get(\"location\", {}).get(\"longitude\", \"N/A\"),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"IP Address\": ip, \"Error\": str(e)}\n",
    "\n",
    "def check_ipgeo_bulk(api_key, ip_list):\n",
    "    \"\"\"Check multiple IPs using IPGeolocation.io.\"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(fetch_ipgeo_data, ip, api_key): ip for ip in ip_list}\n",
    "        \n",
    "        with tqdm(total=len(ip_list), desc=\"    Checking IPGeolocation\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                results.append(future.result())\n",
    "                pbar.update(1)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "#### IPInfo Functions ####\n",
    "def fetch_ipinfo_data(ip, api_key):\n",
    "    \"\"\"Fetch data for a single IP from IPInfo.io.\"\"\"\n",
    "    url = f\"https://api.ipinfo.io/lite/{ip}?token={api_key}\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"IP\": ip,\n",
    "            \"ASN\": data.get(\"asn\", \"N/A\"),\n",
    "            \"Name\": data.get(\"as_name\", \"N/A\"),\n",
    "            \"Domain\": data.get(\"as_domain\", \"N/A\"),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"IP Address\": ip, \"Error\": str(e)}\n",
    "\n",
    "def check_ipinfo_bulk(api_key, ip_list):\n",
    "    \"\"\"Check multiple IPs using IPInfo.io.\"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(fetch_ipinfo_data, ip, api_key): ip for ip in ip_list}\n",
    "        \n",
    "        with tqdm(total=len(ip_list), desc=\"    Checking IPInfo\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                results.append(future.result())\n",
    "                pbar.update(1)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "#### Arrin Functions ####\n",
    "def fetch_arin_data(ip):\n",
    "    \"\"\"\n",
    "    Fetch ARIN RDAP data for a single IP address.\n",
    "    Args:\n",
    "        ip (str): The IP address to query.\n",
    "    Returns:\n",
    "        dict: Extracted fields from the ARIN RDAP data.\n",
    "    \"\"\"\n",
    "    # Query the ARIN RDAP API\n",
    "    rdap_url = f\"https://rdap.arin.net/registry/ip/{ip}\"\n",
    "    try:\n",
    "        response = requests.get(rdap_url, timeout=5)\n",
    "        response.raise_for_status()  # Raise HTTP errors, if any\n",
    "        rdap_data = response.json()  # Parse the JSON response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Return the error message for debugging purposes\n",
    "        return {\"IP\": ip, \"Error\": f\"Failed to query ARIN RDAP: {e}\"}\n",
    "\n",
    "    # Extract relevant fields from the RDAP response\n",
    "    extracted_info = {\n",
    "        \"IP\": ip,\n",
    "        \"Source Registry\": rdap_data.get(\"handle\", \"Not Provided\"),\n",
    "        \"Net Range\": f\"{rdap_data.get('startAddress', 'Not Provided')} - {rdap_data.get('endAddress', 'Not Provided')}\",\n",
    "        \"CIDR\": (\n",
    "            rdap_data[\"cidr0_cidrs\"][0].get(\"v4prefix\", \"Not Provided\")\n",
    "            if \"cidr0_cidrs\" in rdap_data and isinstance(rdap_data[\"cidr0_cidrs\"], list)\n",
    "            else \"Not Provided\"\n",
    "        ),\n",
    "        \"Net Name\": rdap_data.get(\"name\", \"Not Provided\"),\n",
    "        \"Net Type\": rdap_data.get(\"type\", \"Not Provided\"),\n",
    "        \"Registration Date\": rdap_data.get(\"registrationDate\", \"Not Provided\"),\n",
    "        \"Last Changed\": rdap_data.get(\"lastChanged\", \"Not Provided\"),\n",
    "    }\n",
    "\n",
    "    # Handle related entities\n",
    "    related_entities = []\n",
    "    for entity in rdap_data.get(\"entities\", []):\n",
    "        entity_info = {\n",
    "            \"Full Name\": \"Not Provided\",\n",
    "            \"Roles\": \", \".join(entity.get(\"roles\", [])),\n",
    "        }\n",
    "        vcard_array = entity.get(\"vcardArray\", [])\n",
    "        if len(vcard_array) > 1 and isinstance(vcard_array[1], list):\n",
    "            for field in vcard_array[1]:\n",
    "                if field[0] == \"fn\":  # Full Name\n",
    "                    entity_info[\"Full Name\"] = field[3] if len(field) > 3 else \"Not Provided\"\n",
    "                elif field[0] == \"adr\":  # Address\n",
    "                    entity_info[\"Address\"] = \", \".join(field[3]) if len(field) > 3 else \"Not Provided\"\n",
    "                elif field[0] == \"email\":  # Email\n",
    "                    entity_info[\"Emails\"] = field[3]\n",
    "                elif field[0] == \"tel\":  # Telephone\n",
    "                    entity_info[\"Telephones\"] = field[3]\n",
    "        related_entities.append(entity_info)\n",
    "\n",
    "    extracted_info[\"Related Entities\"] = related_entities\n",
    "\n",
    "    return extracted_info\n",
    "\n",
    "def check_arin_bulk(ip_list):\n",
    "    \"\"\"\n",
    "    Check multiple IPs using ARIN RDAP.\n",
    "    Args:\n",
    "        ip_list (list): A list of IP addresses to query.\n",
    "    Returns:\n",
    "        pandas.DataFrame: Results from ARIN RDAP queries.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(fetch_arin_data, ip): ip for ip in ip_list}\n",
    "      \n",
    "        with tqdm(total=len(ip_list), desc=\"    Checking ARIN RDAP\") as pbar:\n",
    "            for future in as_completed(futures):\n",
    "                results.append(future.result())\n",
    "                pbar.update(1)\n",
    "    return pd.DataFrame(results)\n",
    "    \n",
    "###################################\n",
    "# CLICK EVENT HANDLERS FOR BUTTONS #\n",
    "###################################\n",
    "def on_click_export(b):\n",
    "    global exported_df  # Reference the global DataFrame\n",
    "    with output:\n",
    "        output.clear_output()  # Clear the output area\n",
    "        if exported_df is not None:  # Check if data exists\n",
    "            try:\n",
    "                # Convert DataFrame to CSV and encode it in base64\n",
    "                csv_data = exported_df.to_csv(index=False)\n",
    "                b64_csv = base64.b64encode(csv_data.encode()).decode()\n",
    "\n",
    "                # Generate a downloadable link\n",
    "                filename = f\"exported_table_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "                payload = f\"data:text/csv;base64,{b64_csv}\"\n",
    "                html = f\"\"\"\n",
    "                    <a download=\"{filename}\" href=\"{payload}\" target=\"_blank\" style=\"font-size: 16px; color: green;\">\n",
    "                        ✅ File '{filename}' is ready. Click here to download.\n",
    "                    </a>\n",
    "                \"\"\"\n",
    "                # Automatically trigger download with a JavaScript auto-click\n",
    "                display(HTML(html))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ An error occurred while exporting: {e}\")\n",
    "        else:\n",
    "            print(\"⚠️ No table available to export. Please generate a table first.\")\n",
    "            \n",
    "def on_click_abuseipdb(b):\n",
    "    global exported_df\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        ip_list = [ip.strip() for ip in ip_input.value.split(',') if ip.strip()]\n",
    "        if not ip_list:\n",
    "            print(\"⚠️ Please enter at least one IP.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"🔍 AbuseIPDb | Started check of {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        df = check_abuseipdb_bulk(api_key_abuseipdb, ip_list)\n",
    "\n",
    "        # Timing and performance metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0    \n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "\n",
    "        # Save the merged DataFrame to the global variable\n",
    "        exported_df = df\n",
    "        \n",
    "        styled_df = df.style.set_table_styles(\n",
    "            [{\n",
    "                'selector': 'th',  # Apply to header cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }, {\n",
    "                'selector': 'td',  # Apply to data cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }])\n",
    "            \n",
    "        # Display the styled DataFrame\n",
    "        display(styled_df)\n",
    "\n",
    "def on_click_ipgeo(b):\n",
    "    global exported_df\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        ip_list = [ip.strip() for ip in ip_input.value.split(',') if ip.strip()]\n",
    "        if not ip_list:\n",
    "            print(\"⚠️ Please enter at least one IP.\")\n",
    "            return\n",
    "            \n",
    "        print(f\"🔍 IPGeo | Started check of {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        df = check_ipgeo_bulk(api_key_ipgeo, ip_list)\n",
    "\n",
    "        # Timing and performance metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0    \n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "\n",
    "        # Save the merged DataFrame to the global variable\n",
    "        exported_df = df\n",
    "        \n",
    "        styled_df = df.style.set_table_styles(\n",
    "            [{\n",
    "                'selector': 'th',  # Apply to header cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }, {\n",
    "                'selector': 'td',  # Apply to data cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }])\n",
    "            \n",
    "        # Display the styled DataFrame\n",
    "        display(styled_df)\n",
    "\n",
    "def on_click_ipinfo(b):\n",
    "    global exported_df\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        ip_list = [ip.strip() for ip in ip_input.value.split(',') if ip.strip()]\n",
    "        if not ip_list:\n",
    "            print(\"⚠️ Please enter at least one IP.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"🔍 IPInfo | Started check of {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        df = check_ipinfo_bulk(api_key_ipinfo, ip_list)\n",
    "\n",
    "        # Timing and performance metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0    \n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "\n",
    "        # Save the merged DataFrame to the global variable\n",
    "        exported_df = df\n",
    "        \n",
    "        styled_df = df.style.set_table_styles(\n",
    "            [{\n",
    "                'selector': 'th',  # Apply to header cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }, {\n",
    "                'selector': 'td',  # Apply to data cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }])\n",
    "            \n",
    "        # Display the styled DataFrame\n",
    "        display(styled_df)\n",
    "\n",
    "def on_click_arin(b):\n",
    "    global exported_df\n",
    "    with output:\n",
    "        output.clear_output()  # Clear the previous output\n",
    "        ip_list = [ip.strip() for ip in ip_input.value.split(',') if ip.strip()]\n",
    "        if not ip_list:\n",
    "            print(\"⚠️ Please enter at least one IP.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"🔍 ARIN | Started checking {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Perform bulk ARIN lookup\n",
    "        df = check_arin_bulk(ip_list)\n",
    "\n",
    "        # Timing metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0\n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "\n",
    "        # Save results to the global variable\n",
    "        exported_df = df\n",
    "        \n",
    "        # Display the results\n",
    "        styled_df = df.style.set_table_styles(\n",
    "            [{\n",
    "                'selector': 'th',  # Apply styling to headers\n",
    "                'props': [('text-align', 'left')]\n",
    "            }, {\n",
    "                'selector': 'td',  # Apply styling to table cells\n",
    "                'props': [('text-align', 'left')]\n",
    "            }])\n",
    "\n",
    "        # Display the styled DataFrame\n",
    "        display(styled_df)\n",
    "    \n",
    "def on_click_all(b):\n",
    "    global exported_df\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        ip_list = [ip.strip() for ip in ip_input.value.split(',') if ip.strip()]\n",
    "        if not ip_list:\n",
    "            print(\"⚠️ Please enter at least one IP.\")\n",
    "            return\n",
    "\n",
    "        # IPAbuseDb\n",
    "        print(f\"\\n🔍 IPAbuseDb | Started check of {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "            \n",
    "        abuse_df = check_abuseipdb_bulk(api_key_abuseipdb, ip_list)\n",
    "\n",
    "        # Timing and performance metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0    \n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "        \n",
    "        # Debug\n",
    "        #display(abuse_df)\n",
    "\n",
    "        # IPGeo\n",
    "        print(f\"\\n🔍 IPGeo | Started check of {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        ipgeo_df = check_ipgeo_bulk(api_key_ipgeo, ip_list)\n",
    "\n",
    "        # Timing and performance metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0    \n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "        \n",
    "        # Debug\n",
    "        #display(ipgeo_df)\n",
    "\n",
    "        # IPInfo\n",
    "        print(f\"\\n🔍 IPInfo | Started check of {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        ipinfo_df = check_ipinfo_bulk(api_key_ipinfo, ip_list)\n",
    "\n",
    "        # Timing and performance metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0    \n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "            \n",
    "        # Debug\n",
    "        #display(ipinfo_df)\n",
    "\n",
    "        # Arin\n",
    "        print(f\"\\n🔍 ARIN RDAP | Started checking {len(ip_list)} IPs at {time.strftime('%b %d %H:%M:%S', time.localtime())}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Perform bulk ARIN lookup\n",
    "        arin_df = check_arin_bulk(ip_list)\n",
    "\n",
    "        # Timing metrics\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        elapsed_minutes, elapsed_seconds = divmod(elapsed_time, 60)\n",
    "        avg_time_per_ip = round(elapsed_time / len(ip_list), 1) if len(ip_list) > 0 else 0\n",
    "        print(f\"    ✅ Completed check at {time.strftime('%b %d %H:%M:%S', time.localtime(end_time))}\")\n",
    "        print(f\"    ⏱ Time elapsed: {int(elapsed_minutes)} minutes and {elapsed_seconds:.1f} seconds\")\n",
    "        print(f\"    ⏱ Average time per IP checked: {avg_time_per_ip} seconds\")\n",
    "\n",
    "        # Debug\n",
    "        #display(arrin_df)\n",
    "        \n",
    "        print(\"\\n🔗 Merging results into a single table...\")\n",
    "        merged_df = pd.merge(abuse_df, ipgeo_df, on='IP', how='outer')\n",
    "        merged_df = pd.merge(merged_df, ipinfo_df, on='IP', how='outer')\n",
    "        merged_df = pd.merge(merged_df, arin_df, on='IP', how='outer')\n",
    "\n",
    "        # Save the merged DataFrame to the global variable\n",
    "        exported_df = merged_df\n",
    "        \n",
    "        # Add a MultiIndex header to designate column sources\n",
    "        merged_df.columns = pd.MultiIndex.from_tuples(\n",
    "            [\n",
    "                (\"IPAbuseDB\", col) if col in abuse_df.columns else\n",
    "                (\"IPGeo\", col) if col in ipgeo_df.columns else\n",
    "                (\"IPInfo\", col) if col in ipinfo_df.columns else\n",
    "                (\"ARIN\", col) if col in arin_df.columns else\n",
    "                (\"Other\", col)  # Fallback for unexpected columns\n",
    "                for col in merged_df.columns\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        def header_style():\n",
    "            return [\n",
    "                {\n",
    "                    'selector': 'thead th.level0',  # Top-level header row (MultiIndex first level)\n",
    "                    'props': [('background-color', '#f2f2f2'),  # Light gray\n",
    "                              ('color', 'black'),                 # Black text\n",
    "                              ('text-align', 'center'),           # Center-align\n",
    "                              ('font-weight', 'bold')             # Bold font\n",
    "                    ]\n",
    "                },\n",
    "                {\n",
    "                    'selector': 'thead th.level1',  # Second-level header row (column names)\n",
    "                    'props': [('background-color', '#e3e3e3'),  # Lighter gray\n",
    "                              ('color', 'black'),               # Black text\n",
    "                              ('text-align', 'center')]         # Center-align\n",
    "                }\n",
    "            ]\n",
    "\n",
    "        # Define a styler function to style the cell backgrounds\n",
    "        def style_table(data):\n",
    "            # Highlight cells based on their source (first-level MultiIndex)\n",
    "            styles = pd.DataFrame('', index=data.index, columns=data.columns)\n",
    "\n",
    "            for source in data.columns.get_level_values(0).unique():  # Level 0 is the source\n",
    "                if source == \"IPAbuseDB\":\n",
    "                    styles.loc[:, source] = 'background-color: #ffcccc; text-align: center;'  # Light red\n",
    "                elif source == \"IPGeo\":\n",
    "                    styles.loc[:, source] = 'background-color: #ccffcc; text-align: center;'  # Light green\n",
    "                elif source == \"IPInfo\":\n",
    "                    styles.loc[:, source] = 'background-color: #ccccff; text-align: center;'  # Light blue\n",
    "                elif source == \"ARIN\":\n",
    "                    styles.loc[:, source] = 'background-color: #ffffcc; text-align: center;'  # Light yellow\n",
    "                else:\n",
    "                    styles.loc[:, source] = 'background-color: #f0f0f0; text-align: center;'  # Light gray for others\n",
    "            return styles\n",
    "\n",
    "        # Apply styles to the DataFrame\n",
    "        styled_df = merged_df.style.set_table_styles(header_style()).apply(\n",
    "            style_table, axis=None)\n",
    "        \n",
    "        display(styled_df)\n",
    "\n",
    "def on_click_clear(b):\n",
    "    output.clear_output()\n",
    "\n",
    "######################\n",
    "# GUI IMPLEMENTATION #\n",
    "######################\n",
    "# Widgets\n",
    "ip_input = widgets.Text(\n",
    "    placeholder='Enter IP(s), separated by commas',\n",
    "    description='IP(s):',\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "output = Output()\n",
    "\n",
    "# Buttons for services\n",
    "run_button_abuseipdb = widgets.Button(description='Check AbuseIPDB', button_style='success')\n",
    "run_button_ipgeo = widgets.Button(description='Check IPGeo', button_style='success')\n",
    "run_button_ipinfo = widgets.Button(description='Check IPInfo', button_style='success')\n",
    "run_button_arin = widgets.Button(description='Check ARIN', button_style='success')\n",
    "run_button_all = widgets.Button(description='Check All', button_style='primary')\n",
    "clear_button = widgets.Button(description='Clear Output', button_style='danger')\n",
    "export_button = widgets.Button(description='Export to CSV', button_style='info')\n",
    "\n",
    "# Button event bindings\n",
    "run_button_abuseipdb.on_click(on_click_abuseipdb)\n",
    "run_button_ipgeo.on_click(on_click_ipgeo)\n",
    "run_button_ipinfo.on_click(on_click_ipinfo)\n",
    "run_button_arin.on_click(on_click_arin)\n",
    "run_button_all.on_click(on_click_all)\n",
    "clear_button.on_click(on_click_clear)\n",
    "export_button.on_click(on_click_export)\n",
    "\n",
    "##############\n",
    "# APP LAYOUT #\n",
    "##############\n",
    "app_layout = VBox([\n",
    "    widgets.HTML(\"<h2>IP Lookup Tool</h2>\"),\n",
    "    ip_input,\n",
    "    HBox([run_button_abuseipdb, run_button_ipgeo, run_button_ipinfo, run_button_arin, run_button_all, clear_button, export_button]),\n",
    "    output\n",
    "])\n",
    "\n",
    "# Display the App\n",
    "display(app_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6c626-ef67-4e74-bae9-7c19545f5bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
